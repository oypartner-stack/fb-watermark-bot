import os
import json
import subprocess
import re
import urllib.request
from xml.etree import ElementTree as ET
import cloudinary
import cloudinary.uploader
import requests

# â”€â”€â”€ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PAGE_ID = "61584143603071"
LAST_IDS_FILE = "processed_ids.json"
COOKIES_FILE = "/tmp/cookies.txt"
WATERMARK_PUBLIC_ID = "fes_ceel2l"
WEBHOOK_URL = os.environ["WEBHOOK_URL"]

cloudinary.config(
    cloud_name = os.environ["CLOUDINARY_CLOUD_NAME"],
    api_key    = os.environ["CLOUDINARY_API_KEY"],
    api_secret = os.environ["CLOUDINARY_API_SECRET"],
)

# â”€â”€â”€ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_processed_ids():
    try:
        with open(LAST_IDS_FILE, "r") as f:
            return json.load(f)
    except:
        return []

def save_processed_ids(ids):
    with open(LAST_IDS_FILE, "w") as f:
        json.dump(ids[-50:], f)

# â”€â”€â”€ Ø¬Ù„Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø¹Ø¨Ø± RSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_latest_videos():
    print("ğŸ” Ø¬Ù„Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø¹Ø¨Ø± RSS...")

    rss_url = f"https://www.facebook.com/feeds/page.php?id={PAGE_ID}&format=rss20"

    videos = []
    try:
        req = urllib.request.Request(
            rss_url,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        )
        with urllib.request.urlopen(req, timeout=15) as r:
            content = r.read()

        root = ET.fromstring(content)
        items = root.findall('.//item')
        print(f"âœ… RSS: ÙˆØ¬Ø¯Ù†Ø§ {len(items)} Ø¹Ù†ØµØ±")

        for item in items[:5]:
            link = item.findtext('link') or ''
            title = item.findtext('title') or 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†'
            guid = item.findtext('guid') or link
            description = item.findtext('description') or ''

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù‘Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
            vid_id = None
            # Ø¨Ø­Ø« Ø¹Ù† video_id ÙÙŠ Ø§Ù„Ø±Ø§Ø¨Ø·
            match = re.search(r'videos?/(\d+)', link)
            if match:
                vid_id = match.group(1)
            else:
                match = re.search(r'v=(\d+)', link)
                if match:
                    vid_id = match.group(1)
                else:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… guid ÙƒÙ…Ø¹Ø±Ù
                    nums = re.sub(r'[^0-9]', '', guid)
                    if len(nums) > 5:
                        vid_id = nums[-15:]

            if vid_id and link:
                videos.append({
                    "id": vid_id,
                    "title": title.strip(),
                    "url": link.strip(),
                })
                print(f"  ğŸ“¹ {vid_id} | {title[:40]}")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ RSS: {str(e)[:200]}")

    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙ†Ø¬Ø­ RSS Ù†Ø¬Ø±Ø¨ Ø¬Ù„Ø¨ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ø¨Ø± yt-dlp Ù…Ø¹ cookies
    if not videos:
        print("ğŸ”„ Ø¬Ø±Ø¨ yt-dlp Ù…Ø¹ cookies...")
        urls_to_try = [
            f"https://www.facebook.com/{PAGE_ID}/videos",
            f"https://www.facebook.com/profile.php?id={PAGE_ID}",
        ]
        for url in urls_to_try:
            result = subprocess.run([
                "yt-dlp",
                "--cookies", COOKIES_FILE,
                "--flat-playlist",
                "--playlist-items", "1:5",
                "--print", "%(id)s|%(title)s|%(webpage_url)s",
                "--no-warnings",
                url
            ], capture_output=True, text=True, timeout=60)

            for line in result.stdout.strip().split("\n"):
                if "|" in line:
                    parts = line.split("|", 2)
                    if len(parts) == 3:
                        vid_id, title, vid_url = parts
                        if vid_id and vid_url:
                            videos.append({
                                "id": vid_id.strip(),
                                "title": title.strip() or "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†",
                                "url": vid_url.strip(),
                            })

            if videos:
                print(f"âœ… yt-dlp: ØªÙ… Ø¬Ù„Ø¨ {len(videos)} ÙÙŠØ¯ÙŠÙˆ")
                break

    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª: {len(videos)}")
    return videos

# â”€â”€â”€ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚Ø§Ù„Ø¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_video(video):
    print(f"â¬‡ï¸ ØªØ­Ù…ÙŠÙ„: {video['title'][:50]}")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    result = subprocess.run([
        "yt-dlp",
        "--cookies", COOKIES_FILE,
        "-o", "/tmp/video.mp4",
        "--format", "best[ext=mp4]/best",
        "--no-warnings",
        video["url"]
    ], capture_output=True, text=True, timeout=300)

    if not os.path.exists("/tmp/video.mp4"):
        print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {result.stderr[:200]}")
        return None

    print("ğŸ¨ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø´ÙØ§Ù...")

    # Ø¬Ù„Ø¨ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    probe = subprocess.run([
        "ffprobe", "-v", "quiet",
        "-print_format", "json",
        "-show_streams", "/tmp/video.mp4"
    ], capture_output=True, text=True)

    try:
        info = json.loads(probe.stdout)
        vstream = next((s for s in info["streams"] if s["codec_type"] == "video"), None)
        w = vstream["width"] if vstream else 1080
        h = vstream["height"] if vstream else 1920
    except:
        w, h = 1080, 1920

    print(f"ğŸ“ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {w}x{h}")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ù…Ù† Cloudinary
    watermark_url = f"https://res.cloudinary.com/{os.environ['CLOUDINARY_CLOUD_NAME']}/image/upload/{WATERMARK_PUBLIC_ID}.png"
    subprocess.run(
        ["wget", "-q", "-O", "/tmp/watermark.png", watermark_url],
        timeout=30
    )

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¨Ù†ÙØ³ Ø­Ø¬Ù… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    result = subprocess.run([
        "ffmpeg", "-y",
        "-i", "/tmp/video.mp4",
        "-i", "/tmp/watermark.png",
        "-filter_complex", f"[1:v]scale={w}:{h}[wm];[0:v][wm]overlay=0:0",
        "-codec:a", "copy",
        "-preset", "fast",
        "/tmp/output.mp4"
    ], capture_output=True, text=True, timeout=600)

    if not os.path.exists("/tmp/output.mp4"):
        print(f"âŒ ÙØ´Ù„ ffmpeg: {result.stderr[:200]}")
        return None

    print("â˜ï¸ Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„ Ø¹Ù„Ù‰ Cloudinary...")
    upload_result = cloudinary.uploader.upload(
        "/tmp/output.mp4",
        resource_type="video",
        public_id="processed_video",
        overwrite=True,
    )

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    for f in ["/tmp/video.mp4", "/tmp/output.mp4", "/tmp/watermark.png"]:
        if os.path.exists(f):
            os.remove(f)

    return upload_result["secure_url"]

# â”€â”€â”€ Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù€ Webhook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_to_webhook(video_url, title):
    print("ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù€ Webhook...")
    response = requests.post(WEBHOOK_URL, json={
        "video_url": video_url,
        "title": title
    }, timeout=30)
    print(f"âœ… ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„: {response.status_code}")

# â”€â”€â”€ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ¤– Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª...")
processed_ids = load_processed_ids()
print(f"ğŸ“‹ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹: {len(processed_ids)}")

videos = get_latest_videos()

if not videos:
    print("âŒ Ù„Ù… ÙŠØªÙ… Ø¬Ù„Ø¨ Ø£ÙŠ ÙÙŠØ¯ÙŠÙˆ")
else:
    new_video = None
    for v in videos:
        if v["id"] not in processed_ids:
            new_video = v
            break

    if not new_video:
        print("â„¹ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠØ¯ÙŠÙˆ Ø¬Ø¯ÙŠØ¯")
    else:
        print(f"ğŸ†• ÙÙŠØ¯ÙŠÙˆ Ø¬Ø¯ÙŠØ¯: {new_video['title'][:60]}")
        final_url = process_video(new_video)
        if final_url:
            send_to_webhook(final_url, new_video["title"])
            processed_ids.append(new_video["id"])
            save_processed_ids(processed_ids)
            print("ğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
        else:
            print("âŒ ÙØ´Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")
